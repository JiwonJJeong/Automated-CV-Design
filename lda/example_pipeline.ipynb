{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Automated CV Design: Example Pipeline\n",
                "\n",
                "This notebook demonstrates a complete workflow for processing pairwise distance data, including:\n",
                "1. **Data Loading**: Using the refactored `data_access` to load H5/NPY files.\n",
                "2. **Variance Filtering**: Removing low-variance features.\n",
                "3. **MPSO Feature Selection**: Projecting features using Multi-objective Particle Swarm Optimization.\n",
                "4. **Dimension Reduction**: Applying Fisher's Linear Discriminant Analysis (FLDA)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import importlib.util\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "def import_module_from_path(module_name, path):\n",
                "    \"\"\"Helper to import modules from paths that aren't valid Python identifiers (e.g. starting with numbers)\"\"\"\n",
                "    # Get absolute path\n",
                "    abs_path = os.path.abspath(path)\n",
                "    spec = importlib.util.spec_from_file_location(module_name, abs_path)\n",
                "    module = importlib.util.module_from_spec(spec)\n",
                "    sys.modules[module_name] = module\n",
                "    spec.loader.exec_module(module)\n",
                "    return module\n",
                "\n",
                "# Since the notebook is in 'lda/', we can import data_access directly\n",
                "import data_access as da\n",
                "\n",
                "# Import modules from numeric subdirectories\n",
                "variance = import_module_from_path(\"variance\", \"2_feature_extraction/variance.py\")\n",
                "MPSO = import_module_from_path(\"MPSO\", \"3_feature_selection/3.5.MPSO.py\")\n",
                "FLDA = import_module_from_path(\"FLDA\", \"4_dimensionality_reduction/FLDA.py\")\n",
                "\n",
                "print(\"Modules imported successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "\n",
                "We use the `data_iterator` to load snapshots from our H5/NPY distance maps. This handled both formats transparently."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define your base directory for data (local or absolute)\n",
                "base_dir = '../data/dist_maps'\n",
                "\n",
                "# Initialize the data iterator\n",
                "raw_data_iter = da.data_iterator(base_dir=base_dir, chunk_size=5000)\n",
                "\n",
                "print(f\"Created data iterator for: {base_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Variance Filtering\n",
                "\n",
                "We apply a variance threshold (using the knee-point method) to filter out static or irrelevant distance pairs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the two-pass variance filter\n",
                "# Pass 1: Analyzes total variance across all chunks\n",
                "# Pass 2: Yields filtered DataFrames\n",
                "filtered_iter = variance.variance_filter_pipeline(raw_data_iter)\n",
                "\n",
                "print(\"Variance filter applied. Ready for feature selection.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Label Assignment (TODO)\n",
                "\n",
                "Before running supervised feature selection (MPSO) or dimensionality reduction (FLDA), you MUST assign class labels to each sample."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_target_labels(df_iter):\n",
                "    \"\"\"\n",
                "    TODO: Implement logic to assign classes to each sample.\n",
                "    Classes could be based on construct names, frame ranges, or other metadata.\n",
                "    \"\"\"\n",
                "    for df in df_iter:\n",
                "        # EXAMPLE FILLER: Assigning a dummy class based on replica\n",
                "        # Replace this with your actual classification logic\n",
                "        df['class'] = (df['replica'].astype(int) % 2) + 1  # FLDA often expects integers starting at 1\n",
                "        yield df\n",
                "\n",
                "labeled_iter = add_target_labels(filtered_iter)\n",
                "print(\"Labels added to the pipeline (Placeholder logic used).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. MPSO Feature Selection\n",
                "\n",
                "MPSO finds the best projection of features to separate your classes using Particle Swarm Optimization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# MPSO consumes the iterator and returns a single projected DataFrame\n",
                "# Adjust dims and iterations as needed for your dataset\n",
                "mpso_result_df = MPSO.run_mpso_pipeline(\n",
                "    labeled_iter, \n",
                "    target_col='class', \n",
                "    dims=10,        # Number of features to project into\n",
                "    mpso_iters=20   # Iterations for demo efficiency\n",
                ")\n",
                "\n",
                "print(f\"MPSO complete. Result shape: {mpso_result_df.shape}\")\n",
                "mpso_result_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. FLDA Dimensionality Reduction\n",
                "\n",
                "Finally, we apply Fisher's LDA to the selected features to find the optimal global discriminant subspace."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply FLDA\n",
                "flda_iter = FLDA.run_flda(\n",
                "    mpso_result_df, \n",
                "    num_eigenvector=2, \n",
                "    target_col='class'\n",
                ")\n",
                "\n",
                "# FLDA returns an iterator yielding the final transformed DataFrame\n",
                "final_lda_df = next(flda_iter)\n",
                "\n",
                "print(\"FLDA Transformation Complete.\")\n",
                "final_lda_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualization\n",
                "\n",
                "Plot the final CV (Collective Variable) space."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "for cls in final_lda_df['class'].unique():\n",
                "    mask = final_lda_df['class'] == cls\n",
                "    plt.scatter(final_lda_df.loc[mask, 'LD1'], final_lda_df.loc[mask, 'LD2'], label=f'Class {cls}', alpha=0.6)\n",
                "\n",
                "plt.xlabel('CV 1 (LD1)')\n",
                "plt.ylabel('CV 2 (LD2)')\n",
                "plt.title('Final CV Space (FLDA)')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}